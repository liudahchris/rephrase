{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF For Topic Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../../data/lyrics/data/subset_bof.csv'\n",
    "df = pd.read_csv(path,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>the</th>\n",
       "      <th>you</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>a</th>\n",
       "      <th>me</th>\n",
       "      <th>it</th>\n",
       "      <th>not</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>motivo</th>\n",
       "      <th>bake</th>\n",
       "      <th>insist</th>\n",
       "      <th>wel</th>\n",
       "      <th>santo</th>\n",
       "      <th>pe</th>\n",
       "      <th>gee</th>\n",
       "      <th>colleg</th>\n",
       "      <th>kad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAYYAU128F92D58D0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRARURM128F931A91B</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAMSSK128F92FDC80</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAMPA128F92E7D0D</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAWHZK12903CB5A01</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       i   the  you   to  and     a   me    it  not   in ...   \\\n",
       "TRAYYAU128F92D58D0   0.0   3.0  4.0  2.0  4.0   5.0  0.0   0.0  7.0  0.0 ...    \n",
       "TRARURM128F931A91B   5.0   5.0  9.0  2.0  0.0   4.0  0.0   1.0  2.0  0.0 ...    \n",
       "TRAMSSK128F92FDC80   8.0  13.0  5.0  1.0  6.0   4.0  1.0   0.0  5.0  7.0 ...    \n",
       "TRAAMPA128F92E7D0D  17.0   0.0  4.0  4.0  5.0  20.0  8.0  18.0  2.0  0.0 ...    \n",
       "TRAWHZK12903CB5A01  18.0   1.0  3.0  6.0  0.0   2.0  0.0   1.0  5.0  0.0 ...    \n",
       "\n",
       "                    writer  motivo  bake  insist  wel  santo   pe  gee  \\\n",
       "TRAYYAU128F92D58D0     0.0     0.0   0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "TRARURM128F931A91B     0.0     0.0   0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "TRAMSSK128F92FDC80     0.0     0.0   0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "TRAAMPA128F92E7D0D     0.0     0.0   0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "TRAWHZK12903CB5A01     0.0     0.0   0.0     0.0  0.0    0.0  0.0  0.0   \n",
       "\n",
       "                    colleg  kad  \n",
       "TRAYYAU128F92D58D0     0.0  0.0  \n",
       "TRARURM128F931A91B     0.0  0.0  \n",
       "TRAMSSK128F92FDC80     0.0  0.0  \n",
       "TRAAMPA128F92E7D0D     0.0  0.0  \n",
       "TRAWHZK12903CB5A01     0.0  0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Sparse Is Our Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99460578204103389"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df==0).sum().sum()/np.product(df.shape).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 15\n",
    "iters = 10000\n",
    "nmf = NMF(n_components=n,init='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset = df.values[:,:1500]\n",
    "W = nmf.fit_transform(df)\n",
    "H=nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask=np.array([row[::-1] for row in np.argsort(H,axis=1)])[:,:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible = np.array(df.columns)[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = np.array([[word for word in topic  if word not in stopwords.words('english')] for topic in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['want', 'tri', 'make', 'got', 'would', 'time', 'back', 'could', 'life', 'one']\n",
      "['let', 'go', 'tell', 'get', 'like', 'yeah', 'take', 'got', 'ya', 'right']\n",
      "['love', 'know', 'see', 'think', 'want', 'feel', 'never', 'would', 'heart', 'chang']\n",
      "['get', 'like', 'come', 'littl', 'caus', 'top', 'got', 'man', 'ya', 'bitch']\n",
      "['go', 'oh', 'us', 'never', 'thing', 'day', 'everi', 'togeth', 'know', 'live']\n",
      "['come', 'get', 'said', 'start', 'could', 'eye', 'one', 'right', 'say', 'caus']\n",
      "['que', 'de', 'la', 'te', 'tu', 'en', 'el', 'mi', 'un', 'yo']\n",
      "['ca', 'go', 'know', 'babi', 'got', 'wanna', 'ai', 'wo', 'realli', 'thing']\n",
      "['da', 'like', 'niggaz', 'next', 'fuck', 'na', 'wish', 'want', 'drink', 'rhyme']\n",
      "['head', 'one', 'see', 'like', 'say', 'light', 'world', 'nigga', 'follow', 'fuck']\n",
      "['love', 'babi', 'let', 'come', 'help', 'tell', 'call', 'girl', 'go', 'make']\n",
      "['oh', 'hood', 'life', 'hous', 'love', 'babi', 'got', 'heart', 'nigga', 'would']\n",
      "['ich', 'und', 'denk', 'du', 'die', 'nicht', 'das', 'es', 'der', 'ist']\n",
      "['whi', 'love', 'hot', 'song', 'say', 'ca', 'life', 'time', 'coz', 'everyth']\n",
      "['know', 'never', 'like', 'get', 'would', 'caus', 'see', 'need', 'feel', 'gonna']\n"
     ]
    }
   ],
   "source": [
    "for topic in filtered:\n",
    "    print topic[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Try LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 15\n",
    "lda = LDA(n_topics=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherliu/anaconda/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_jobs=1, n_topics=25, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'get', 'got', 'nigga', 'make', 'shit', 'caus', 'em', 'back', 'yo', 'ya', 'head']\n",
      "['love', 'know', 'would', 'one', 'tell', 'time', 'thing', 'make', 'got', 'could', 'see', 'feel']\n",
      "['hey', 'us', 'wish', 'wrong', 'year', 'christma', 'go', 'get', 'hope', 'right', 'wo', 'thing']\n",
      "['know', 'ca', 'want', 'never', 'say', 'go', 'whi', 'away', 'feel', 'get', 'like', 'gonna']\n",
      "['oh', 'ah', 'whoa', 'ooh', 'night', 'bye', 'ay', 'lone', 'take', 'slip', 'pure', 'thrill']\n",
      "['fall', 'kill', 'miss', 'rainbow', 'jingl', 'jah', 'favor', 'aim', 'total', 'twenti', 'thru', 'wont']\n",
      "['cri', 'goodby', 'anymor', 'lover', 'spend', 'aint', 'stranger', 'im', 'dont', 'cant', 'late', 'harder']\n",
      "['saturday', 'sunday', 'special', 'friday', 'basta', 'tuesday', 'sugar', 'aye', 'afternoon', 'pon', 'bonni', 'gi']\n",
      "['countri', 'dig', 'slap', 'jungl', 'oo', 'circumst', 'cotton', 'main', 'victim', 'ow', 'fun', 'rocket']\n",
      "['la', 'de', 'je', 'et', 'les', 'le', 'pas', 'des', 'un', 'dan', 'qui', 'pour']\n",
      "['que', 'de', 'la', 'te', 'en', 'el', 'tu', 'mi', 'yo', 'es', 'un', 'quiero']\n",
      "['ich', 'und', 'du', 'die', 'das', 'dem', 'der', 'nicht', 'ist', 'es', 'mich', 'auf']\n",
      "['onc', 'flesh', 'whisper', 'resist', 'gaze', '2x', 'chao', 'oper', 'linda', 'thirst', 'niin', 'held']\n",
      "['da', 'e', 'di', 'mi', 'nuh', 'la', 'fine', 'uno', 'che', 'bo', 'chi', 'gent']\n",
      "['men', 'lyric', 'som', 'till', 'har', 'det', 'ur', 'vi', 'sol', 'dum', 'nu', 'av']\n",
      "['man', 'rememb', 'daddi', 'ohh', 'chorus', 'suicid', 'start', 'gal', 'die', 'ahh', 'hang', 'stori']\n",
      "['na', 'eu', 'oi', 'meu', 'cantar', 'quero', 'pra', 'sem', 'seu', 'em', 'com', 'vou']\n",
      "['come', 'danc', 'home', 'light', 'night', 'welcom', 'sail', 'side', 'superman', 'hole', 'whenev', 'ecstasi']\n",
      "['girl', 'gone', 'woman', 'bad', 'talk', 'right', 'worri', 'river', 'boy', 'ask', 'got', 'mari']\n",
      "['eye', 'run', 'road', 'hand', 'breath', 'dead', 'arm', 'close', 'blood', 'red', 'saw', 'watch']\n",
      "['yeah', 'alright', 'round', 'aliv', 'nah', 'darl', 'well', 'brown', 'honey', 'lovin', 'said', 'walkin']\n",
      "['day', 'one', 'world', 'life', 'god', 'lord', 'see', 'night', 'light', 'sky', 'die', 'burn']\n",
      "['babi', 'go', 'let', 'ya', 'rock', 'gonna', 'get', 'uh', 'roll', 'hot', 'pleas', 'gotta']\n",
      "['&', 'n', 'satellit', 'tv', 'teenag', 'whatcha', 'civil', 'ed', 'cousin', 'appreci', 'hon', 'scienc']\n",
      "['said', 'old', 'look', 'time', 'lie', 'way', 'song', 'say', 'good', 'man', 'hous', 'could']\n"
     ]
    }
   ],
   "source": [
    "components = lda.components_\n",
    "mask=np.array([row[::-1] for row in np.argsort(components,axis=1)])[:,:100]\n",
    "possible = np.array(df.columns)[mask]\n",
    "filtered = np.array([[word for word in topic  if word not in stopwords.words('english')] for topic in possible])\n",
    "\n",
    "for topic in filtered:\n",
    "    print topic[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
